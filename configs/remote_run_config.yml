training:
    ############### you need to check every time #################
    num_epochs: 320
    batch_size: 1024
    learning_rate: 0.0004
    sample_per_ep: 32
    checkpoint_per_epoch: 32

    noise_level: 0.15
    ema: 0.9999 # only for const schedule
    ####################### end check ############################

    warmup_steps: 25000 # 20 ep for bs1024
    log_per_step: 100

    optimizer: adamw
    adam_b1: 0.9
    adam_b2: 0.95
    weight_decay: 0.0

    # ema_halflife_kimg: 500 # edm
    # wandb: False # use this to disable wandb

    ema_schedule: const # or edm
    lr_schedule: const
model:
    name: TSNF_Small_p2_b8_l8_S_2
    teacher_dropout: 0.0
    # student_dropout: 0.1 # not supported now
    # prior_norm: 0.5 # not supported now

    loss_weight: uniform # options: norm, uniform
    label_drop_rate: 0.1
    clip_range_teacher: 1.0
teacher: # for load teacher
    name: NF_Small_p2_b8_l8
    dropout: 0.0 # TODO: check this dp
fid:
    on_use: True
    fid_times: 10
    # num_samples: 50000 # 50k
    num_samples: 5000
    guidance: 0.0 # 0 for with label
    guidance_method: x # not supported now
    # sanity_teacher: True

load_teacher_from: /kmh-nfs-us-mount/logs/sqa/sqa_Flow_matching/20250516_154421_edg7t8_kmh-tpuvm-v4-32-preemptible-yiyang__b_lr_ep_eval/checkpoint_800640 # NF 47: bs1024, n0.15, clip ma 1, lr4e-4, 640ep

# load_from: null
# search_cfg: True
# just_evaluate: True # use this to just evaluate the model (without training)
# just_prior: True # teacher generate image, then student generate latent
save_by_fid: True

wandb_notes: "noise 0.15 clip ma T vit S"